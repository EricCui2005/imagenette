{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.models import Model\n",
    "from keras.utils import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (64, 64))  # Consistent size\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    for path in tqdm(image_paths, desc=\"Loading images\"):\n",
    "        img = load_image(path)\n",
    "        if img is not None:  # Check if image was loaded successfully\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Failed to load image: {path}\")\n",
    "    \n",
    "    print(\"Images Loaded. Stacking into numpy array...\")\n",
    "    \n",
    "    # Convert to numpy array with explicit shape\n",
    "    return np.stack(images)  # Use np.stack with progress tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data loading strings\n",
    "train_image_label_csv = '/Users/ericcui/repos/imagenette/imagenette2-320/train_imagenette.csv'\n",
    "val_image_label_csv = \"/Users/ericcui/repos/imagenette/imagenette2-320/val_imagenette.csv\"\n",
    "path_prefix = \"/Users/ericcui/repos/imagenette/imagenette2-320/\"\n",
    "\n",
    "# Label to index mappings\n",
    "label_index_mappings = {\n",
    "    \"n01440764\": 0,\n",
    "    \"n02102040\": 1,\n",
    "    \"n02979186\": 2,\n",
    "    \"n03000684\": 3,\n",
    "    \"n03028079\": 4,\n",
    "    \"n03394916\": 5,\n",
    "    \"n03417042\": 6,\n",
    "    \"n03425413\": 7,\n",
    "    \"n03445777\": 8,\n",
    "    \"n03888257\": 9,\n",
    "}\n",
    "\n",
    "# Label to class mappings\n",
    "class_mappings = {\n",
    "    \"n01440764\": \"tench\",\n",
    "    \"n02102040\": \"English springer\",\n",
    "    \"n02979186\": \"cassette player\",\n",
    "    \"n03000684\": \"chain saw\",\n",
    "    \"n03028079\": \"church\",\n",
    "    \"n03394916\": \"French horn\",\n",
    "    \"n03417042\": \"garbage truck\",\n",
    "    \"n03425413\": \"gas pump\",\n",
    "    \"n03445777\": \"golf ball\",\n",
    "    \"n03888257\": \"parachute\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training dataframe\n",
    "train_df = pd.read_csv(train_image_label_csv)\n",
    "\n",
    "# Loading training images\n",
    "image_paths = train_df['path'].tolist()\n",
    "image_paths = [path_prefix + path for path in image_paths]\n",
    "train_images = load_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading validation dataframe\n",
    "test_df = pd.read_csv(val_image_label_csv)\n",
    "\n",
    "# Loading validatino images\n",
    "test_image_paths = test_df['path'].tolist()\n",
    "test_image_paths = [path_prefix + path for path in test_image_paths]\n",
    "test_images = load_images(test_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['noisy_labels_0'].tolist()\n",
    "train_labels = np.array([label_index_mappings[label] for label in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_df['noisy_labels_0'].tolist()\n",
    "test_labels = np.array([label_index_mappings[label] for label in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering Image and Label Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['tench', 'English springer', 'cassette player', 'chain saw', 'church', 'French horn', 'garbage truck', 'gas pump', 'golf ball', 'parachute']\n",
    "\n",
    "# Select 25 random indices from the training set\n",
    "random_indices = np.random.choice(len(train_images), size=25, replace=False)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[idx])\n",
    "    plt.xlabel(class_names[train_labels[idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Adding a convolutional layer with 32 filters of size 3x3\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64,64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adding a convolutional layer with 64 filters of size 3x3\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adding a convolutional layer with 64 filters of size 3x3\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Dense Layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# Printing model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map Rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_feature_maps(feature_maps, output_dir, square=8):\n",
    "    \"\"\"\n",
    "    Save feature maps from a convolutional layer as jpeg images\n",
    "    \n",
    "    Args:\n",
    "        feature_maps: numpy array of shape (1, height, width, n_filters)\n",
    "        output_dir: directory to save the feature map images\n",
    "        square: number of feature maps to save\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(min(square * square, feature_maps.shape[-1])):\n",
    "        # Normalize to 0-255 range\n",
    "        fm = feature_maps[0, :, :, i]\n",
    "        fm = ((fm - fm.min()) * 255 / (fm.max() - fm.min())).astype(np.uint8)\n",
    "        \n",
    "        # Convert to PIL Image and save\n",
    "        img = Image.fromarray(fm)\n",
    "        img.save(os.path.join(output_dir, f'feature_map_{i}.jpg'))\n",
    "\n",
    "def plot_feature_maps(feature_maps, square=8, figsize=(20, 20)):\n",
    "    \"\"\"\n",
    "    Plot feature maps from a convolutional layer\n",
    "    \n",
    "    Args:\n",
    "        feature_maps: numpy array of shape (1, height, width, n_filters)\n",
    "        square: number of feature maps per row/column\n",
    "        figsize: size of the figure\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i in range(min(square * square, feature_maps.shape[-1])):\n",
    "        ax = plt.subplot(square, square, i + 1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(feature_maps[0, :, :, i], cmap='gray')\n",
    "        plt.title(f'Filter {i}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rendering Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/Users/ericcui/repos/imagenette/imagenette2-320/train/n02102040/ILSVRC2012_val_00000665.JPEG\"\n",
    "\n",
    "# Use the function\n",
    "model_activations = Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "img = load_img(img_path, target_size=(64, 64))\n",
    "img = img_to_array(img)\n",
    "img = img.reshape(1, 64, 64, 3)\n",
    "feature_maps = model_activations.predict(img)\n",
    "plot_feature_maps(feature_maps)\n",
    "save_feature_maps(feature_maps, \"feature_maps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path with timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_path = f\"cnn_model_{timestamp}.h5\"\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
