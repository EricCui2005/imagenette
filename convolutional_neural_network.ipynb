{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# # Normalize pixel values to be between 0 and 1\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_label_csv = '/Users/ericcui/repos/imagenette/imagenette2-320/train_imagenette.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>noisy_labels_0</th>\n",
       "      <th>noisy_labels_1</th>\n",
       "      <th>noisy_labels_5</th>\n",
       "      <th>noisy_labels_25</th>\n",
       "      <th>noisy_labels_50</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/n02979186/n02979186_9036.JPEG</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/n02979186/n02979186_11957.JPEG</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n03000684</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/n02979186/n02979186_9715.JPEG</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n03417042</td>\n",
       "      <td>n03000684</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/n02979186/n02979186_21736.JPEG</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n03417042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/n02979186/ILSVRC2012_val_00046953.JPEG</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n02979186</td>\n",
       "      <td>n03394916</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           path noisy_labels_0 noisy_labels_1  \\\n",
       "0           train/n02979186/n02979186_9036.JPEG      n02979186      n02979186   \n",
       "1          train/n02979186/n02979186_11957.JPEG      n02979186      n02979186   \n",
       "2           train/n02979186/n02979186_9715.JPEG      n02979186      n02979186   \n",
       "3          train/n02979186/n02979186_21736.JPEG      n02979186      n02979186   \n",
       "4  train/n02979186/ILSVRC2012_val_00046953.JPEG      n02979186      n02979186   \n",
       "\n",
       "  noisy_labels_5 noisy_labels_25 noisy_labels_50  is_valid  \n",
       "0      n02979186       n02979186       n02979186     False  \n",
       "1      n02979186       n02979186       n03000684     False  \n",
       "2      n02979186       n03417042       n03000684     False  \n",
       "3      n02979186       n02979186       n03417042     False  \n",
       "4      n02979186       n02979186       n03394916     False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_image_label_csv)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"/Users/ericcui/repos/imagenette/imagenette2-320/\"\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (426, 320))  # Consistent size\n",
    "    return img\n",
    "\n",
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    for path in tqdm(image_paths, desc=\"Loading images\"):\n",
    "        img = load_image(path)\n",
    "        if img is not None:  # Check if image was loaded successfully\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Failed to load image: {path}\")\n",
    "    \n",
    "    print(\"Images Loaded. Stacking into numpy array...\")\n",
    "    \n",
    "    # Convert to numpy array with explicit shape\n",
    "    return np.stack(images, desc=\"Converting to numpy array\")  # Use np.stack with progress tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 9469/9469 [00:12<00:00, 740.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Loaded. Stacking into numpy array...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to numpy array: 100%|██████████| 9469/9469 [00:00<00:00, 3867926.04it/s]\n"
     ]
    }
   ],
   "source": [
    "image_paths = train_df['path'].tolist()\n",
    "image_paths = [path_prefix + path for path in image_paths]\n",
    "train_images = load_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label to index mappings\n",
    "label_index_mappings = {\n",
    "    \"n01440764\": 0,\n",
    "    \"n02102040\": 1,\n",
    "    \"n02979186\": 2,\n",
    "    \"n03000684\": 3,\n",
    "    \"n03028079\": 4,\n",
    "    \"n03394916\": 5,\n",
    "    \"n03417042\": 6,\n",
    "    \"n03425413\": 7,\n",
    "    \"n03445777\": 8,\n",
    "    \"n03888257\": 9,\n",
    "}\n",
    "\n",
    "# Label to class mappings\n",
    "class_mappings = {\n",
    "    \"n01440764\": \"tench\",\n",
    "    \"n02102040\": \"English springer\",\n",
    "    \"n02979186\": \"cassette player\",\n",
    "    \"n03000684\": \"chain saw\",\n",
    "    \"n03028079\": \"church\",\n",
    "    \"n03394916\": \"French horn\",\n",
    "    \"n03417042\": \"garbage truck\",\n",
    "    \"n03425413\": \"gas pump\",\n",
    "    \"n03445777\": \"golf ball\",\n",
    "    \"n03888257\": \"parachute\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['noisy_labels_0'].tolist()\n",
    "train_labels = [label_index_mappings[label] for label in train_labels]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering CIFAR-10 Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Adding a convolutional layer with 32 filters of size 3x3\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adding a convolutional layer with 64 filters of size 3x3\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adding a convolutional layer with 64 filters of size 3x3\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Dense Layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
