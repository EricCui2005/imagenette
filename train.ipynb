{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch as torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class Definition and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax image classifier class\n",
    "class SoftmaxClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SoftmaxClassifier, self).__init__()\n",
    "        \n",
    "        # Single fully connected layer\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Compute raw logits\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "# Function to get the input dimension of a colored image\n",
    "def get_input_dim(image_path):\n",
    "    img_array = cv2.imread(image_path)\n",
    "    flattened_array = img_array.reshape(-1)\n",
    "    return len(flattened_array)\n",
    "\n",
    "# Function to flatten a colored image into a 1D array\n",
    "def flatten_image(image_path):\n",
    "    img_array = cv2.imread(image_path)\n",
    "    img_array = cv2.resize(img_array, (426, 320))\n",
    "    flattened_array = img_array.reshape(-1)\n",
    "    return flattened_array\n",
    "\n",
    "# Count total files in directory and subdirectories\n",
    "def count_files(directory):\n",
    "    total = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total += len(files)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous Testing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "init_image_path = \"/Users/ericcui/repos/imagenette/imagenette2-320/train/n01440764/ILSVRC2012_val_00000293.JPEG\"\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "\n",
    "# CSV processing configuration\n",
    "train_image_label_csv = \"/Users/ericcui/repos/imagenette/imagenette2-320/train_imagenette.csv\"\n",
    "path_prefix = \"/Users/ericcui/repos/imagenette/imagenette2-320/\"\n",
    "\n",
    "# Label to index mappings\n",
    "label_index_mappings = {\n",
    "    \"n01440764\": 0,\n",
    "    \"n02102040\": 1,\n",
    "    \"n02979186\": 2,\n",
    "    \"n03000684\": 3,\n",
    "    \"n03028079\": 4,\n",
    "    \"n03394916\": 5,\n",
    "    \"n03417042\": 6,\n",
    "    \"n03425413\": 7,\n",
    "    \"n03445777\": 8,\n",
    "    \"n03888257\": 9,\n",
    "}\n",
    "\n",
    "# Label to class mappings\n",
    "class_mappings = {\n",
    "    \"n01440764\": \"tench\",\n",
    "    \"n02102040\": \"English springer\",\n",
    "    \"n02979186\": \"cassette player\",\n",
    "    \"n03000684\": \"chain saw\",\n",
    "    \"n03028079\": \"church\",\n",
    "    \"n03394916\": \"French horn\",\n",
    "    \"n03417042\": \"garbage truck\",\n",
    "    \"n03425413\": \"gas pump\",\n",
    "    \"n03445777\": \"golf ball\",\n",
    "    \"n03888257\": \"parachute\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize an image to 426x320\n",
    "def resize_image(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Resize to 426x320\n",
    "    resized_img = cv2.resize(img, (426, 320))\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "# Using OpenCV (cv2)\n",
    "def save_as_jpeg_cv2(numpy_array, output_path):\n",
    "    \"\"\"\n",
    "    Save a numpy array as a JPEG image.\n",
    "    \n",
    "    Args:\n",
    "        numpy_array: NumPy array of image (height, width, 3) in BGR format\n",
    "        output_path: String path where to save the image (e.g., 'output.jpg')\n",
    "    \"\"\"\n",
    "    success = cv2.imwrite(output_path, numpy_array)\n",
    "    if success:\n",
    "        print(f\"Image successfully saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"Failed to save image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "base_learning_rate = 0.001\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the softmax classifier\n",
    "input_dim = get_input_dim(init_image_path)\n",
    "softmax_classifier = SoftmaxClassifier(input_dim, num_classes)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.Adam(softmax_classifier.parameters(), lr=base_learning_rate)\n",
    "\n",
    "# Read the CSV file containing image paths and labels\n",
    "df = pd.read_csv(train_image_label_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert images from image paths to flattened tensors in a batch dataframe\n",
    "def process_batch_images(batch_df):\n",
    "    images = batch_df['path'].tolist()\n",
    "    images = [path_prefix + path for path in images]\n",
    "    images = [flatten_image(path) for path in images]\n",
    "    \n",
    "    images = [torch.tensor(img, dtype=torch.float32) for img in images]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "batch_df = df.iloc[0:32]\n",
    "images = process_batch_images(batch_df)\n",
    "labels = batch_df['noisy_labels_0'].tolist()[:32]\n",
    "# Convert string labels to indices using labels_index_mappings\n",
    "labels = [label_index_mappings[label] for label in labels]\n",
    "\n",
    "# Forward pass\n",
    "outputs = softmax_classifier(torch.stack(images))\n",
    "\n",
    "loss = nn.functional.cross_entropy(outputs, torch.tensor(labels))\n",
    "\n",
    "# Backward pass and optimization\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 1/296 [00:00<00:42,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 32\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 3/296 [00:00<00:30,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 64\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 96\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 128\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 5/296 [00:00<00:25, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 160\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 7/296 [00:00<00:42,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 192\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 224\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 10/296 [00:01<00:35,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 256\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 288\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 320\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 12/296 [00:01<00:34,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 352\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 384\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▍         | 14/296 [00:01<00:30,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 416\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 448\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 480\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 18/296 [00:01<00:26, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 512\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 544\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 576\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 20/296 [00:02<00:25, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 608\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 640\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 672\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 24/296 [00:02<00:23, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 704\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 736\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 768\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 26/296 [00:02<00:24, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 800\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 832\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 864\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 30/296 [00:03<00:23, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 896\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 928\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 960\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  11%|█         | 32/296 [00:03<00:23, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 992\n",
      "Batch size: 32\n",
      "Loss: 556765.5000\n",
      "Iteration 1024\n",
      "Batch size: 32\n",
      "Loss: 512425.0000\n",
      "Iteration 1056\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  12%|█▏        | 36/296 [00:03<00:23, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 430773.6562\n",
      "Iteration 1088\n",
      "Batch size: 32\n",
      "Loss: 342972.0312\n",
      "Iteration 1120\n",
      "Batch size: 32\n",
      "Loss: 244261.3281\n",
      "Iteration 1152\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  13%|█▎        | 38/296 [00:03<00:23, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 109373.5234\n",
      "Iteration 1184\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1216\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1248\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 42/296 [00:04<00:24, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1280\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1312\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1344\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  15%|█▍        | 44/296 [00:04<00:23, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1376\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1408\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 46/296 [00:04<00:26,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1440\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1472\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 48/296 [00:04<00:28,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1504\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1536\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 49/296 [00:04<00:27,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1568\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 52/296 [00:05<00:28,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1600\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1632\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1664\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  18%|█▊        | 54/296 [00:05<00:25,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1696\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1728\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1760\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  19%|█▉        | 56/296 [00:05<00:25,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1792\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|█▉        | 59/296 [00:06<00:31,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000\n",
      "Iteration 1824\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1856\n",
      "Batch size: 32\n",
      "Loss: 0.0000\n",
      "Iteration 1888\n",
      "Batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|█▉        | 59/296 [00:06<00:25,  9.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Convert images and labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m images = \u001b[43mprocess_batch_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m labels = batch_df[\u001b[33m'\u001b[39m\u001b[33mnoisy_labels_0\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m     12\u001b[39m labels = [label_index_mappings[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mprocess_batch_images\u001b[39m\u001b[34m(batch_df)\u001b[39m\n\u001b[32m      3\u001b[39m images = batch_df[\u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m      4\u001b[39m images = [path_prefix + path \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m images = [\u001b[43mflatten_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[32m      7\u001b[39m images = [torch.tensor(img, dtype=torch.float32) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m images\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mflatten_image\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflatten_image\u001b[39m(image_path):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     img_array = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     img_array = cv2.resize(img_array, (\u001b[32m426\u001b[39m, \u001b[32m320\u001b[39m))\n\u001b[32m     25\u001b[39m     flattened_array = img_array.reshape(-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(df), batch_size), desc=\"Training Progress\"):\n",
    "        \n",
    "        # Get batch data\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Convert images and labels\n",
    "        images = process_batch_images(batch_df)\n",
    "        labels = batch_df['noisy_labels_0'].tolist()\n",
    "        labels = [label_index_mappings[label] for label in labels]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = softmax_classifier(torch.stack(images))\n",
    "        loss = nn.functional.cross_entropy(outputs, torch.tensor(labels))\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
